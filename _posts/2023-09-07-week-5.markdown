---
title: Week 5
subtitle: subtitle
layout: default
modal-id: 5
date: 2023-09-07
img: roundicons.png
thumbnail: roundicons-thumbnail.png
alt: image-alt
project-date: 03 September - 08 September
client: Start Bootstrap
category: Web Development
description: lorem ipsum
---

This week, I created a web scraper to collect auction data from multiple auction websites. I used python libraries like BeautifulSoup, results, pandas and cvs to do web scraping and visualize the collected data.

I began by learning about the basics of web scraping and common ethical considerations related to the field. Then I tried following some tutorials to scrape data from websites made for learning web scraping. I particularly liked [this tutorial](https://realpython.com/python-web-scraping-practical-introduction/) by Real Python, which introduced concepts in an engaging manner and helped me understand the rationale behind each step. 

For my project, I collected information about the auctions of works by a single artist only. I collected this data from the websites of [Bonhams](https://www.bonhams.com/) and [Sotheby's](https://www.sothebys.com/en/?locale=en).

I quickly learned that the methods I used to collect html snippets before were ineffective for collecting information from websites that use javascript to load front-end content. I mainly worked using the BeautifulSoup library, which is insufficient for scraping javascript-rendered pages. So, I used [Selenium](https://www.selenium.dev/),  a software which automates web applications. It offers another advantage - while many webpages load content only when a user scrolls, Selenium automatically scrolls to the end. Therefore, when data is scraped using Selenium, the entire HTML file is loaded.

In Bonhams' website, all information about auctions related to a specific artist can be searched for. At first, I collected data from this page only. However, the information available on this page is quite limited - only the title of the work, the link of the auction, as well as the estimated price can be found. I wanted to learn when the paintings were auctioned, so I then visited the url given for each work, and collected additional information. Using the information obtained, I created tables and downloaded them as Excel files. I used a similar methodology to collect information from Sotheby's' website.

You can see some screenshots of my work below:

<figure>
    <img src="img/portfolio/week-5/code-for-bonhams.png" class="img-responsive img-centered" alt="">
    
    <!---
    <figcaption>Caption for the image.</figcaption>
    --->

</figure>

<figure>
    <img src="img/portfolio/week-5/bonhams-table.png" class="img-responsive img-centered" alt="">
    
    <!---
    <figcaption>Caption for the image.</figcaption>
    --->

</figure>

<figure>
    <img src="img/portfolio/week-5/sothebys-excel.png" class="img-responsive img-centered" alt="">
    
    <!---
    <figcaption>Caption for the image.</figcaption>
    --->

</figure>


The work I have done is far from perfect, and I think I could imporve results by dedicating more time to this project. However, I am happy I was able to learn a new skill, and look forward to using this knowledge in the future.